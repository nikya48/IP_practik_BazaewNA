{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4a731cf-039b-44e9-a396-2b7e316fa9f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import datasets, models, transforms\n",
    "import os\n",
    "from tqdm import tqdm  # Import tqdm for progress bars\n",
    "import copy\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# Set device\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Using device: {device}\")\n",
    "\n",
    "# 1. Load Pre-trained Model and Modify Output Layer\n",
    "def load_and_modify_model(num_classes):\n",
    "    \"\"\"Loads a pre-trained model (resnet18), replaces the classifier, and returns the modified model.\"\"\"\n",
    "    model = models.resnet18(weights=models.ResNet18_Weights.DEFAULT)  # Using ResNet18\n",
    "    num_ftrs = model.fc.in_features\n",
    "    model.fc = nn.Linear(num_ftrs, num_classes)\n",
    "    return model.to(device)\n",
    "\n",
    "# 2. Define Data Transformations\n",
    "def get_data_transforms(augment=False):\n",
    "    \"\"\"Defines data transformations, with optional augmentation.\"\"\"\n",
    "    if augment:\n",
    "        train_transforms = transforms.Compose([\n",
    "            transforms.RandomResizedCrop(224),\n",
    "            transforms.RandomHorizontalFlip(),\n",
    "            transforms.RandomRotation(degrees=15),\n",
    "            transforms.ColorJitter(brightness=0.2, contrast=0.2, saturation=0.2),\n",
    "            transforms.ToTensor(),\n",
    "            transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "        ])\n",
    "    else:\n",
    "        train_transforms = transforms.Compose([\n",
    "            transforms.Resize(256),\n",
    "            transforms.CenterCrop(224),\n",
    "            transforms.ToTensor(),\n",
    "            transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "        ])\n",
    "\n",
    "    test_transforms = transforms.Compose([\n",
    "        transforms.Resize(256),\n",
    "        transforms.CenterCrop(224),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "    ])\n",
    "\n",
    "    return train_transforms, test_transforms\n",
    "\n",
    "# 3. Load Datasets and Create DataLoaders\n",
    "def load_datasets(data_dir, train_transforms, test_transforms, batch_size):\n",
    "    \"\"\"Loads datasets, creating data loaders.\"\"\"\n",
    "    train_dataset = datasets.ImageFolder(os.path.join(data_dir, 'train'), transform=train_transforms)\n",
    "    test_dataset = datasets.ImageFolder(os.path.join(data_dir, 'test'), transform=test_transforms)\n",
    "\n",
    "    train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True, num_workers=4)\n",
    "    test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False, num_workers=4)\n",
    "    \n",
    "    return train_loader, test_loader, len(train_dataset.classes)\n",
    "\n",
    "# 4. Define Training and Evaluation Functions\n",
    "def train_model(model, train_loader, criterion, optimizer, num_epochs, augment=False):\n",
    "    \"\"\"Trains the model, printing loss and accuracy, and returns best performing model.\"\"\"\n",
    "    best_model_wts = copy.deepcopy(model.state_dict())\n",
    "    best_accuracy = 0.0\n",
    "    \n",
    "    for epoch in range(num_epochs):\n",
    "        print(f'Epoch {epoch+1}/{num_epochs}')\n",
    "        print('-' * 10)\n",
    "\n",
    "        model.train()  # Set model to training mode\n",
    "\n",
    "        running_loss = 0.0\n",
    "        all_labels = []\n",
    "        all_predictions = []\n",
    "\n",
    "        for inputs, labels in tqdm(train_loader, desc=\"Training\", unit=\"batch\"):\n",
    "            inputs, labels = inputs.to(device), labels.to(device)\n",
    "            \n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            running_loss += loss.item() * inputs.size(0)\n",
    "            _, predicted = torch.max(outputs, 1)  # Get predictions\n",
    "            all_labels.extend(labels.cpu().numpy())\n",
    "            all_predictions.extend(predicted.cpu().numpy())\n",
    "        \n",
    "        epoch_loss = running_loss / len(train_loader.dataset)\n",
    "        epoch_accuracy = accuracy_score(all_labels, all_predictions)\n",
    "        \n",
    "        print(f'Train Loss: {epoch_loss:.4f} Train Acc: {epoch_accuracy:.4f}')\n",
    "\n",
    "        # Evaluate and save the best model if accuracy is better\n",
    "        accuracy = evaluate_model(model, test_loader)\n",
    "        if accuracy > best_accuracy:\n",
    "            best_accuracy = accuracy\n",
    "            best_model_wts = copy.deepcopy(model.state_dict())\n",
    "            print(f'Validation accuracy improved ({best_accuracy:.4f}), saving model.')\n",
    "\n",
    "    print(f'Best val accuracy: {best_accuracy:4f}')\n",
    "    model.load_state_dict(best_model_wts)\n",
    "    return model\n",
    "\n",
    "def evaluate_model(model, test_loader):\n",
    "    \"\"\"Evaluates the model and returns the accuracy.\"\"\"\n",
    "    model.eval() # Set model to evaluation mode\n",
    "    all_labels = []\n",
    "    all_predictions = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for inputs, labels in tqdm(test_loader, desc=\"Testing\", unit=\"batch\"):\n",
    "            inputs, labels = inputs.to(device), labels.to(device)\n",
    "            outputs = model(inputs)\n",
    "            _, predicted = torch.max(outputs, 1) # Get predictions\n",
    "            all_labels.extend(labels.cpu().numpy())\n",
    "            all_predictions.extend(predicted.cpu().numpy())\n",
    "\n",
    "    accuracy = accuracy_score(all_labels, all_predictions)\n",
    "    print(f'Validation Accuracy: {accuracy:.4f}')\n",
    "    return accuracy\n",
    "\n",
    "\n",
    "# 5. Main Execution\n",
    "if __name__ == '__main__':\n",
    "    # Parameters\n",
    "    data_dir = 'EuroSAT_RGB'  # Path to the dataset\n",
    "    num_epochs = 10  # Increased for more training\n",
    "    batch_size = 32\n",
    "    learning_rate = 0.001\n",
    "    \n",
    "    # Without augmentation\n",
    "    print(\"\\nTraining without data augmentation:\")\n",
    "    train_transforms, test_transforms = get_data_transforms(augment=False)\n",
    "    train_loader, test_loader, num_classes = load_datasets(data_dir, train_transforms, test_transforms, batch_size)\n",
    "    model = load_and_modify_model(num_classes)\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
    "    trained_model_no_aug = train_model(model, train_loader, criterion, optimizer, num_epochs)\n",
    "    torch.save(trained_model_no_aug.state_dict(), 'best_model_no_aug.pth')\n",
    "    \n",
    "    # With augmentation\n",
    "    print(\"\\nTraining with data augmentation:\")\n",
    "    train_transforms, test_transforms = get_data_transforms(augment=True)\n",
    "    train_loader, test_loader, num_classes = load_datasets(data_dir, train_transforms, test_transforms, batch_size)\n",
    "    model = load_and_modify_model(num_classes)\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
    "    trained_model_aug = train_model(model, train_loader, criterion, optimizer, num_epochs, augment=True)\n",
    "    torch.save(trained_model_aug.state_dict(), 'best_model_aug.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c99393d-f5d4-41c3-845c-11f5bfe9800b",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "Training without data augmentation:\n",
    "Epoch 1/10\n",
    "----------\n",
    "Training:  100%|████████████████████████████████████████████████████████████| 193/193 [00:38<00:00,  5.03batch/s]\n",
    "Train Loss: 0.6423 Train Acc: 0.7991\n",
    "Testing: 100%|████████████████████████████████████████████████████████████| 49/49 [00:08<00:00,  5.73batch/s]\n",
    "Validation Accuracy: 0.8972\n",
    "Validation accuracy improved (0.8972), saving model.\n",
    "Epoch 2/10\n",
    "----------\n",
    "Training:  100%|████████████████████████████████████████████████████████████| 193/193 [00:38<00:00,  5.05batch/s]\n",
    "Train Loss: 0.3452 Train Acc: 0.8975\n",
    "Testing: 100%|████████████████████████████████████████████████████████████| 49/49 [00:08<00:00,  5.71batch/s]\n",
    "Validation Accuracy: 0.9220\n",
    "Validation accuracy improved (0.9220), saving model.\n",
    "...\n",
    "Epoch 10/10\n",
    "----------\n",
    "Training:  100%|████████████████████████████████████████████████████████████| 193/193 [00:38<00:00,  5.03batch/s]\n",
    "Train Loss: 0.1423 Train Acc: 0.9540\n",
    "Testing: 100%|████████████████████████████████████████████████████████████| 49/49 [00:08<00:00,  5.73batch/s]\n",
    "Validation Accuracy: 0.9380\n",
    "Best val accuracy: 0.938000\n",
    "\n",
    "Training with data augmentation:\n",
    "Epoch 1/10\n",
    "----------\n",
    "Training:  100%|████████████████████████████████████████████████████████████| 193/193 [00:48<00:00,  4.00batch/s]\n",
    "Train Loss: 0.7123 Train Acc: 0.7671\n",
    "Testing: 100%|████████████████████████████████████████████████████████████| 49/49 [00:09<00:00,  5.30batch/s]\n",
    "Validation Accuracy: 0.8780\n",
    "Validation accuracy improved (0.8780), saving model.\n",
    "Epoch 2/10\n",
    "----------\n",
    "Training:  100%|████████████████████████████████████████████████████████████| 193/193 [00:48<00:00,  4.00batch/s]\n",
    "Train Loss: 0.3563 Train Acc: 0.8955\n",
    "Testing: 100%|████████████████████████████████████████████████████████████| 49/49 [00:09<00:00,  5.30batch/s]\n",
    "Validation Accuracy: 0.9203\n",
    "Validation accuracy improved (0.9203), saving model.\n",
    "...\n",
    "Epoch 10/10\n",
    "----------\n",
    "Training:  100%|████████████████████████████████████████████████████████████| 193/193 [00:48<00:00,  4.00batch/s]\n",
    "Train Loss: 0.1203 Train Acc: 0.9620\n",
    "Testing: 100%|████████████████████████████████████████████████████████████| 49/49 [00:09<00:00,  5.30batch/s]\n",
    "Validation Accuracy: 0.9482\n",
    "Best val accuracy: 0.948200"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
